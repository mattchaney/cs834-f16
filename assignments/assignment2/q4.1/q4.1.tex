\section{Question 4.1}

\subsection{Question}
\input{q4.1/q4.1.txt}

\subsection{Resources}
The textbook \textit{Search Engines: Information Retrieval in Practice} \cite{seirip}, the Python programming language \cite{python} with the python libraries Beautiful Soup \cite{py:beautifulsoup} and NLTK \cite{py:nltk}, and the R programming language \cite{rlang} were used to answer this question.

\subsection{Answer}
The wc.py script found in Listing \ref{listing:wordcount} was used to locate each file of the Wikipedia collection obtained from the book download page, available at \url{http://www.search-engines-book.com}.  The BeautifulSoup library was used to strip out the HTML tags and then the nltk library \cite{py:nltk} was used to tokenize the text.  The individual words were counted manually and the nltk library \cite{py:nltk} was used to count the bigrams.

The word count graph can be found in Figure \ref{fig:wc}, the bigram count graph can be found in Figure \ref{fig:bigram}, and the combination of the two can be found in Figure \ref{fig:both}.  The buildgraphs.R script was used to create these graphs and can be found in Listing \ref{listing:buildgraphs}.

\begin{figure}[h!]
\centering
\label{fig:wc}
\fbox{\includegraphics[scale=.55]{code/filevisitor/wc.pdf}}
\caption{Word Counts for Small Wikipedia Corpus}
\end{figure}

\begin{figure}[h!]
\centering
\label{fig:bigram}
\fbox{\includegraphics[scale=.55]{code/filevisitor/bg.pdf}}
\caption{Bigram Counts for Small Wikipedia Corpus}
\end{figure}

\begin{figure}[h!]
\centering
\label{fig:both}
\fbox{\includegraphics[scale=.55]{code/filevisitor/both.pdf}}
\caption{Both Word and Bigram Counts for Small Wikipedia Corpus}
\end{figure}
